# Workflows and material to train and perform inference with CW3E's AI-driven high-resolution models
This GitHub repository contains all the necessary materials to process the training datasets, train high-resolution models using both global data and CW3E's high-resolution regional data, and perform inference with the trained models. Each of these tasks requires specific infrastructure components, outlined below:
- Merced (`/data/projects/ML/RegionalAI/`): This infrastructure stores CW3E’s high-resolution reanalysis data at 2-km and 6-km native resolutions, which were transferred from AWARE. Python scripts were used to process these files and generate NetCDF files for training (`./high_res_data/config_wrfcf.py` and `./high_res_data/wrfout_to_cf.py`). This processing included selecting the desired variables, renaming them, and converting units to ensure consistency with ERA5 (see Table [here](https://docs.google.com/spreadsheets/d/15TA4t-N5dIeIn3Kx3Bo6BuS5poX6ssEy/edit?usp=sharing&ouid=118073363116552599590&rtpof=true&sd=true)). The resulting NetCDF files were then transferred to Expanse, where they were converted into `.zarr` format for ingestion by the Anemoi framework. Contact information: Patrick Mulrooney was responsible for transfering from AWARE to MERCED; Dan Steinhoff was responsible for coding the Python scripts and generating the netCDF files; Jorge Baño-Medina was responsible for transfering the netCDF files from MERCED to EXPANSE. MERCED also contained the IVT and IWV netCDF files from ERA5 (`./data/ERA5/`) which were transferred to EXPANSE (`/expanse/nfs/cw3e/cwp167/data/era5/hourly/`). MERCED also stored the WRF 3-km and 6-km datasets (physics-based benchmarks) and PRISM at `./data/`. Python scripts to post-process these fields can be found in their respective sub-folders.
- Expanse (`/expanse/nfs/cw3e/cwp167/projects/regional-ai/`): This infrastructure participates in different stages of the training and validation process. First, it is used to create the `.zarr` files for training and testing. For the global dataset, lat-lon ERA5 files (`/expanse/nfs/cw3e/cwp167/data/era5/hourly/`) were interpolated to the N320 projection (`./data/ERA5-31km/netcdf/`). For the high-resolution data, the `.zarr` files are created by ingesting the netCDF files transfered from MERCED which are available at e.g., `./data/CW3E-6km/netcdf/`. This infrastructure also stores the forecasts from the AI-driven (GLOBAL and STRETCHED-GRID) physical-based (IFS, WRF-9km) and groundtruth (PRISM) models. The original WRF-9km and PRISM files were available at MERCED, respectively, and post-processing scripts are available therein. The AI-driven models were transfered from DeltaAI. Finally, validation also takes part here. The sub-folder `figures` contains the code to reproduce each figure of the manuscript. 
- DeltaAI (`/work/`): This infrastructure is used to train the AI models and perform inference with them. zarr files have to be previously transfered from EXPANSE. Table [here](..) shows the different configurations trained for the 6-km model exploring different hyperparameters.
    - hdd-bduu (`/work/hdd/bduu/`): This directory stores the training .yamls.
    - nvme-bduu (`/work/nvme/bduu/`): This directory stores the training outputs, the zarrs and contains the code to perform inference.
    
